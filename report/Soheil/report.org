#+title: CS-933 Project Report

* Description
In this project we are looking for the human to robot join mapping from a
visual demonstration. A demonstration from a human is provided to the system. We
are also given a URDF file, in which the robot joint configuration is
specified. We are looking for a mapping between the human body and the robot
configuration, given the fact that the morphology of human demonstrator is not
the same as the robot.

In particular, we are interested into solving the /Inverse Kinematics/ problem,
not analytically or using existing algorithms, but by using visual data and find
the best mapping between the human demonstrator's joint, and the robot's
joint. Inverse Kinematics is the problem of finding the robot's joints state
(angle and position) by knowing the position of the end-effector.

A component of this mapping is a Reinforcement Learning method that finds the
best reward function that can guide the robotic manipulator through a desirable
path and leads it to a goal point.


** Given Data
A stream of 13 points position that represent the upper body. 

** Expected Output
A stream of robot's joints position and velocity.

** Evaluation Method
Whether the manipulator follows the task that the human demonstrator intends or not.
The robots that our algorithm will be tested on are Sawyer and Yumi. 

* Reinforcement Learning for Inverse Kinematics
In this section we study how we can formulate the inverse kinematics problem in
a multi dimensional 
** Reinforcement Learning
*** What type of RL algorithm do we need for this project? Why?
*** Soft Actor-Critic (SAC)
SAC is an off-policy RL algorithm that maximizes the entropy regularized
expected return using deep networks. The algorithm is developed to be used for
continuous action space. SAC employs a stable stochastic actor-critic
formulation that adds a layer of stochasticity to DDPG-style approaches. As a
result of this added entropy, we have a better exploration in the environment. 


* Tasks
- [X] Writing the problem description in the git repo
- [X] Collecting demonstration
- [ ] Installing ROS
- [ ] Preparing the data recording system
- [ ] Getting the stream of 3D poses of 13 points
- [ ] Reading the input data, and visualization of them
- [ ] Reading Paul's paper
- [ ] How RL is going to be incorporated into the project, other than as an agent that defines a reward function
- [ ] Reading [[http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf][SAC]]
- [X] Reading [[https://medium.com/analytics-vidhya/learning-to-walk-using-reinforcement-learning-4e237aaf64a0][SAC's blog]]
- [X] Implementing SAC and recording a video
